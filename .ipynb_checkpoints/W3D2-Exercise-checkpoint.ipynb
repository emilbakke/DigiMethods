{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: APIs and Functions II \n",
    "\n",
    "## 4.1 Using the Twitter API to collect data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1.1** Find the Twitter account of the University of Copenhagen's Faculty of Social Science _by hand_ and get their Twitter account information using `tweepy` functionality. Remember that you just started a new Jupyter Notebook, so you will have to load the necessary modules and set up your authentication with the Twitter API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing tweepy and setting up auth\n",
    "import tweepy\n",
    "from AppCred import CONSUMER_KEY, CONSUMER_SECRET\n",
    "from AppCred import ACCESS_TOKEN, ACCESS_TOKEN_SECRET\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "ku_user=api.get_user('uni_copenhagen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1.2** When was this account created? Try to use the `str` and `print` commands to respond with a complete sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The account UniversityCopenhagen was created at 2011-05-12 09:31:02\n"
     ]
    }
   ],
   "source": [
    "print(\"The account \" + ku_user.name + \" was created at \" + str(ku_user.created_at))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1.3** Can you find out 1) where this account is located, 2) how many people are following the account, and 3) how many accounts the account is following?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Copenhagen, Denmark'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ku_user.location\n",
    "#ku_user.followers_count\n",
    "#ku_user.friends_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1.4** Next, get the timeline for this user \"mfroman\". What happens? Can you explain why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TweepError",
     "evalue": "Not authorized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTweepError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-026f499452be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_timeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mfroman'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tweepy\\binder.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    248\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tweepy\\binder.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    231\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mRateLimitError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mTweepError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapi_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mapi_error_code\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m             \u001b[1;31m# Parse the response payload\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTweepError\u001b[0m: Not authorized."
     ]
    }
   ],
   "source": [
    "api.user_timeline('mfroman')\n",
    "# Returns we are not authorized. It is because the Twitter is private/tweets are protected, thus not publically available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1.5** Now, get the timeline for our example account \"vicariousveblen\". Some of the tweets were posted automatically, i.e. using a Python script. Can you tell from the metadata which? How?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, ('For the end of vicarious consumption is to enhance, not the fullness of life of the consumer, but the pecuniary repâ€¦ https://t.co/x2O7ALCem3', '2020-02-18 16:49:23'), ('As has already been indicated, the distinction between exploit and drudgery is an invidious distinction between employments.', '2020-02-18 16:47:23'), ('High-bred manners and ways of living are items of conformity to the norm of conspicuous leisure and conspicuous consumption.', '2020-02-18 16:45:22'), ('Hello World!', '2020-02-18 16:16:46')]\n"
     ]
    }
   ],
   "source": [
    "example_timeline=api.user_timeline('vicariousveblen')\n",
    "#print(example_timeline)\n",
    "\n",
    "timetweet=[0]\n",
    "\n",
    "for tweet in example_timeline:\n",
    "    timetweet.append((tweet.text, str(tweet.created_at)))\n",
    "\n",
    "print(timetweet)\n",
    "    \n",
    "# Looks like the three 'last' tweets were posted using a script. Can tell because they are all posted with 2 minutes between\n",
    "# them, which suggests that a script has a wait-period of two minutes and posting them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Writing and using our own functions to process the Twitter data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2.1** Collect the timeline for this account \"CPH_SODAS\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cph_sodas = api.user_timeline(\"CPH_SODAS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2.2** Write a function that you can use to summarize the tweets in the timelineâ€“feel free to look at the code examples we used earlier today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 'on'),\n",
       " (10, 'RT'),\n",
       " (9, 'and'),\n",
       " (7, 'the'),\n",
       " (5, '@distractdenmark:'),\n",
       " (5, '#machineanthropology'),\n",
       " (4, 'workshop'),\n",
       " (4, 'to'),\n",
       " (4, 'of'),\n",
       " (4, 'in'),\n",
       " (4, 'a'),\n",
       " (3, 'this'),\n",
       " (3, 'social'),\n",
       " (3, 'series'),\n",
       " (3, 'out'),\n",
       " (3, 'is'),\n",
       " (3, 'how'),\n",
       " (3, 'for'),\n",
       " (3, 'first'),\n",
       " (3, 'about'),\n",
       " (3, 'Morten'),\n",
       " (3, 'Axel'),\n",
       " (3, '@suneman'),\n",
       " (3, '&amp;'),\n",
       " (2, 'with'),\n",
       " (2, 'very'),\n",
       " (2, 'theâ€¦'),\n",
       " (2, 'talk'),\n",
       " (2, 'stage'),\n",
       " (2, 'science'),\n",
       " (2, 'our'),\n",
       " (2, 'new'),\n",
       " (2, 'media'),\n",
       " (2, 'have'),\n",
       " (2, 'from'),\n",
       " (2, 'commenting'),\n",
       " (2, 'been'),\n",
       " (2, 'an'),\n",
       " (2, 'The'),\n",
       " (2, 'Pedersen'),\n",
       " (2, 'Machine'),\n",
       " (2, 'MSc'),\n",
       " (2, 'Join'),\n",
       " (2, 'In'),\n",
       " (2, '@andbjn:'),\n",
       " (2, '@RebAdlerNissen'),\n",
       " (2, '@CPH_SODAS'),\n",
       " (1, \"ğŸ“²'Politikere\"),\n",
       " (1, 'you'),\n",
       " (1, 'will'),\n",
       " (1, 'widely'),\n",
       " (1, 'where'),\n",
       " (1, 'well-off'),\n",
       " (1, 'we'),\n",
       " (1, 'want'),\n",
       " (1, 'visited'),\n",
       " (1, 'verdens'),\n",
       " (1, 'various'),\n",
       " (1, 'using'),\n",
       " (1, 'use'),\n",
       " (1, 'us'),\n",
       " (1, 'two'),\n",
       " (1, 'transfer'),\n",
       " (1, 'tools?'),\n",
       " (1, 'thing'),\n",
       " (1, 'their'),\n",
       " (1, 'that'),\n",
       " (1, 'talks'),\n",
       " (1, 'surrounding'),\n",
       " (1, 'study'),\n",
       " (1, 'spring'),\n",
       " (1, 'spread'),\n",
       " (1, 'speakers'),\n",
       " (1, 'some'),\n",
       " (1, 'socialâ€¦'),\n",
       " (1, 'second'),\n",
       " (1, 'scientist'),\n",
       " (1, 'school'),\n",
       " (1, 'revolves'),\n",
       " (1, 'research.'),\n",
       " (1, 'redrawing'),\n",
       " (1, 'reactions'),\n",
       " (1, 'questioâ€¦'),\n",
       " (1, 'question'),\n",
       " (1, 'pÃ¥'),\n",
       " (1, 'project'),\n",
       " (1, 'progâ€¦'),\n",
       " (1, 'program'),\n",
       " (1, 'professor'),\n",
       " (1, 'problem?'),\n",
       " (1, 'presentations'),\n",
       " (1, 'pres'),\n",
       " (1, 'predicting'),\n",
       " (1, 'politics'),\n",
       " (1, 'piece'),\n",
       " (1, 'perspectives'),\n",
       " (1, 'people'),\n",
       " (1, 'participated'),\n",
       " (1, 'og'),\n",
       " (1, 'next'),\n",
       " (1, 'neighborhâ€¦'),\n",
       " (1, 'mobil'),\n",
       " (1, 'mixing'),\n",
       " (1, 'miss'),\n",
       " (1, 'misinformation?'),\n",
       " (1, 'might'),\n",
       " (1, 'methâ€¦'),\n",
       " (1, 'methods.'),\n",
       " (1, 'lecture'),\n",
       " (1, 'kids'),\n",
       " (1, 'just'),\n",
       " (1, 'joint'),\n",
       " (1, 'its'),\n",
       " (1, 'it?'),\n",
       " (1, 'it'),\n",
       " (1, 'issue).'),\n",
       " (1, 'invited'),\n",
       " (1, 'international'),\n",
       " (1, 'interesting'),\n",
       " (1, 'images,'),\n",
       " (1, 'i'),\n",
       " (1, 'https://t.co/hi2vClmf3e'),\n",
       " (1, 'https://t.co/b54dD3HmjC'),\n",
       " (1, 'https://t.co/YvqlQOqFsR'),\n",
       " (1, 'https://t.co/XvslIriVf4'),\n",
       " (1, 'https://t.co/VE1Q1BQsrW'),\n",
       " (1, 'https://t.co/UWN9LsZccd'),\n",
       " (1, 'https://t.co/KaoRrJUG0e'),\n",
       " (1, 'https://t.co/EKO5wosjo1'),\n",
       " (1, 'https://t.co/Arg6Mbg8ms'),\n",
       " (1, 'https://t.co/72RDrSqXâ€¦'),\n",
       " (1, 'https://t.co/62KsL3j8cY'),\n",
       " (1, 'https://t.co/5Emhm5xdNx'),\n",
       " (1, 'https://t.co/2FGpnRtu6Y'),\n",
       " (1, 'host'),\n",
       " (1, 'hele'),\n",
       " (1, 'has'),\n",
       " (1, 'grant!'),\n",
       " (1, 'good'),\n",
       " (1, 'front'),\n",
       " (1, 'forhandlingsrummet'),\n",
       " (1, 'forhandler'),\n",
       " (1, 'foran'),\n",
       " (1, 'fellow'),\n",
       " (1, 'even'),\n",
       " (1, 'episode'),\n",
       " (1, 'emotions'),\n",
       " (1, 'emojis,'),\n",
       " (1, 'does'),\n",
       " (1, 'do'),\n",
       " (1, 'diplomats'),\n",
       " (1, 'developments'),\n",
       " (1, 'decrease'),\n",
       " (1, 'dealing'),\n",
       " (1, 'de'),\n",
       " (1, 'dayâ€™s'),\n",
       " (1, 'days'),\n",
       " (1, 'data'),\n",
       " (1, 'coâ€¦'),\n",
       " (1, 'computational'),\n",
       " (1, 'compaâ€¦'),\n",
       " (1, 'combining'),\n",
       " (1, 'colleagueâ€¦'),\n",
       " (1, 'colleagues.'),\n",
       " (1, 'co-organized'),\n",
       " (1, 'centered'),\n",
       " (1, 'bÃ¥de'),\n",
       " (1, 'by'),\n",
       " (1, 'boundaries'),\n",
       " (1, 'bots'),\n",
       " (1, 'before'),\n",
       " (1, 'befolkning'),\n",
       " (1, 'be?'),\n",
       " (1, 'back'),\n",
       " (1, 'awarded'),\n",
       " (1, 'attendance'),\n",
       " (1, 'at'),\n",
       " (1, 'aspects'),\n",
       " (1, 'as'),\n",
       " (1, 'article'),\n",
       " (1, 'arounâ€¦'),\n",
       " (1, 'around'),\n",
       " (1, 'areâ€¦'),\n",
       " (1, 'ansâ€¦'),\n",
       " (1, 'affect'),\n",
       " (1, 'address'),\n",
       " (1, 'Willadsen'),\n",
       " (1, 'Why'),\n",
       " (1, 'Who'),\n",
       " (1, 'What'),\n",
       " (1, 'Vincent'),\n",
       " (1, 'UCPH'),\n",
       " (1, 'Turns'),\n",
       " (1, 'This'),\n",
       " (1, 'Thick'),\n",
       " (1, 'Testing'),\n",
       " (1, 'Sune'),\n",
       " (1, 'Spring'),\n",
       " (1, 'Social'),\n",
       " (1, 'Series'),\n",
       " (1, 'Say'),\n",
       " (1, 'Sapienza'),\n",
       " (1, 'SODAS'),\n",
       " (1, 'Rebecca'),\n",
       " (1, 'Rayâ€¦'),\n",
       " (1, 'Prof.'),\n",
       " (1, 'Phillip'),\n",
       " (1, 'PhD'),\n",
       " (1, 'Peter'),\n",
       " (1, 'Pedersen,'),\n",
       " (1, 'Passionate'),\n",
       " (1, 'Our'),\n",
       " (1, 'Nicolajsen'),\n",
       " (1, 'News'),\n",
       " (1, 'Networks'),\n",
       " (1, 'Nature'),\n",
       " (1, 'Monday.'),\n",
       " (1, 'Monday'),\n",
       " (1, 'Lehmann'),\n",
       " (1, 'Kristin'),\n",
       " (1, 'Kelton'),\n",
       " (1, 'Iâ¤ï¸@RISjnl'),\n",
       " (1, 'Information'),\n",
       " (1, 'Hendricks'),\n",
       " (1, 'Helene'),\n",
       " (1, 'Hear'),\n",
       " (1, 'Halkier'),\n",
       " (1, 'For'),\n",
       " (1, \"Don't\"),\n",
       " (1, 'Discussion'),\n",
       " (1, 'December'),\n",
       " (1, 'Data+'),\n",
       " (1, 'Data'),\n",
       " (1, 'DISTRACT'),\n",
       " (1, 'Copenhagen.â€¦'),\n",
       " (1, 'Chinese'),\n",
       " (1, 'Check'),\n",
       " (1, 'Can'),\n",
       " (1, 'Bubbles'),\n",
       " (1, 'Brooker'),\n",
       " (1, 'Anthropology'),\n",
       " (1, 'Anna'),\n",
       " (1, 'And'),\n",
       " (1, 'Anabel'),\n",
       " (1, 'Adler-Nissen'),\n",
       " (1, 'AI,'),\n",
       " (1, 'A'),\n",
       " (1, '@fmerhout'),\n",
       " (1, '@daviddlassen,'),\n",
       " (1, '@daviddlassen'),\n",
       " (1, '@TANTlab:'),\n",
       " (1, '@RebAdlerNissen:'),\n",
       " (1, '@RebAdlerNissen,'),\n",
       " (1, \"@It_vest's\"),\n",
       " (1, '@Golovchenko_Yev'),\n",
       " (1, '@DIPâ€¦'),\n",
       " (1, '@Carlsbergfondet:'),\n",
       " (1, '@CPH_SODAS.'),\n",
       " (1, '@AndersKMunk'),\n",
       " (1, '2020'),\n",
       " (1, '(and'),\n",
       " (1, '(1/7)'),\n",
       " (1, \"'thick'â€¦\"),\n",
       " (1, '#thickmachine'),\n",
       " (1, '#segregation?')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Will try to see the most frequently used words used by the account\n",
    "#in order to get an idea of the general nature of their tweets.\n",
    "\n",
    "# Defining function\n",
    "def user_gist(accountname):\n",
    "    #Setting up lists to use\n",
    "    word_freq = {}\n",
    "    word_list = []\n",
    "    gist = []\n",
    "    \n",
    "    #Loop through each tweet in timeline\n",
    "    for tweet in accountname:\n",
    "        tweet_words = tweet.text.split() #splits tweets into separate words\n",
    "        word_list.extend(tweet_words) #words are combined into wordlist using extend command\n",
    "    \n",
    "    #Loop through each word in word_list\n",
    "    for w in word_list:\n",
    "        if w not in word_freq:\n",
    "            word_freq[w] = word_list.count(w)\n",
    "            \n",
    "    #Loop through dictionary, adds each value/key pair to the list\n",
    "    for key in word_freq:\n",
    "        gist.append((word_freq[key], key))\n",
    "        \n",
    "    #Sorting the gist list (goes min -> max)\n",
    "    gist.sort()\n",
    "    \n",
    "    #Sorts gist list by max -> min\n",
    "    gist.reverse()\n",
    "        \n",
    "    return(gist)\n",
    "\n",
    "user_gist(cph_sodas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2.3** Apply the function to the timeline data you collected. Without looking it up, what would you say this account tweets about?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It tweets about workshops and talks presented by SODAS is my guess.\n",
    "# The most common word is 'on', which could be for \"X will gave a talk on X\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Follow Your Interests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.3.1** Identify three Twitter accounts _or_ key words of interest to you. Use the functionality we learned today to look at their history of the accounts, who tweets about your keywords, what do your accounts tweet about etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¤•ç«‹_kazu\n",
      "Abe Fan Tastic\n",
      "ginger cat 93\n",
      "Erre Pi\n",
      "Hacorona Anderson\n",
      "Mar Tirreno\n",
      "Han TV\n",
      "Ettore\n",
      "MLee2ğŸ˜·I Won't Give Up\n",
      "kutarğŸ˜·\n",
      "ğŸ˜·ğŸ˜·ğŸ­\n",
      "Giovanni L. Valenti\n",
      "Hazel Lai\n",
      "Maurizio\n",
      "SK\n"
     ]
    }
   ],
   "source": [
    "# @EsbjergfB + #hongkong + @Astralisgg\n",
    "\n",
    "hk_tweets = api.search(\"#hongkong\")\n",
    "\n",
    "for tweet in hk_tweets:\n",
    "    print(tweet._json['user']['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(11, 'RT'),\n",
       " (7, 'a'),\n",
       " (5, 'the'),\n",
       " (5, 'of'),\n",
       " (4, 'to'),\n",
       " (3, 'sta'),\n",
       " (3, 'si'),\n",
       " (3, 'sesto'),\n",
       " (3, 'mondo'),\n",
       " (3, 'il'),\n",
       " (3, 'focolaio'),\n",
       " (3, 'diventare'),\n",
       " (3, 'dietro'),\n",
       " (3, 'di'),\n",
       " (3, 'come'),\n",
       " (3, 'avviando'),\n",
       " (3, 'al'),\n",
       " (3, 'Paese'),\n",
       " (3, 'Lâ€™Italia'),\n",
       " (3, '@fdragoni:'),\n",
       " (3, '#coronavirus'),\n",
       " (3, '#Hâ€¦'),\n",
       " (3, '#HongKong'),\n",
       " (3, '#Giappone'),\n",
       " (3, '#Corea'),\n",
       " (3, '#Cina'),\n",
       " (2, 'Â·'),\n",
       " (2, 'use'),\n",
       " (2, 'she'),\n",
       " (2, 'saying'),\n",
       " (2, 'report'),\n",
       " (2, 'police'),\n",
       " (2, 'now'),\n",
       " (2, 'in'),\n",
       " (2, 'from'),\n",
       " (2, 'could'),\n",
       " (2, 'confidential'),\n",
       " (2, 'cites'),\n",
       " (2, 'boss,'),\n",
       " (2, 'VR2XAN'),\n",
       " (2, 'Exclusive:'),\n",
       " (2, 'Daily'),\n",
       " (2, 'Apple'),\n",
       " (2, '@ClaudiaMCMo:'),\n",
       " (2, '#é¦™æ¸¯'),\n",
       " (2, '#æ·«'),\n",
       " (2, '#coronâ€¦'),\n",
       " (2, '#HongKongâ€™s'),\n",
       " (2, '#CarrieLam'),\n",
       " (2, '#Beijing'),\n",
       " (1, 'ğŸ–¤FB:'),\n",
       " (1, 'è‡ªå·±å˜…å°æœ‹å‹ä¿‚å¯¶ï¼Œäººåœ°å˜…å°æœ‹å‹ä¿‚è‰ï¼'),\n",
       " (1, 'æ¸¯å¦¹ã€‚ç”Ÿæ´»ğŸ–¤'),\n",
       " (1, 'å¸Œæœ›æœ‰å“¥å“¥å¹«è£œåŠ©é¤Šä¸‹æˆ‘ğŸ¥°ğŸ’•'),\n",
       " (1, 'â€œbubble'),\n",
       " (1, 'â€œOctopusâ€'),\n",
       " (1, 'world'),\n",
       " (1, 'using'),\n",
       " (1, 'theyâ€¦'),\n",
       " (1, 'their'),\n",
       " (1, 'teaâ€'),\n",
       " (1, 'shout'),\n",
       " (1, 'should'),\n",
       " (1, 'sent'),\n",
       " (1, 'said'),\n",
       " (1, 'rises'),\n",
       " (1, 'rights'),\n",
       " (1, 'restaurant'),\n",
       " (1, 'reminded'),\n",
       " (1, 'religious'),\n",
       " (1, 're-think'),\n",
       " (1, 'radical'),\n",
       " (1, 'policy'),\n",
       " (1, 'payment.'),\n",
       " (1, 'out'),\n",
       " (1, 'oppression'),\n",
       " (1, 'oped,'),\n",
       " (1, 'on'),\n",
       " (1, 'new'),\n",
       " (1, 'need'),\n",
       " (1, 'located'),\n",
       " (1, 'lady'),\n",
       " (1, 'inspector'),\n",
       " (1, 'infected'),\n",
       " (1, 'human'),\n",
       " (1, 'https://t.co/zRKK3i81Vx'),\n",
       " (1, 'https://t.co/rRqNYqqAEq'),\n",
       " (1, 'https://t.co/1T2Ko0et2g'),\n",
       " (1, 'health'),\n",
       " (1, 'has'),\n",
       " (1, 'freedom,'),\n",
       " (1, 'force,'),\n",
       " (1, 'for'),\n",
       " (1, 'ex-girâ€¦'),\n",
       " (1, 'dept'),\n",
       " (1, 'customers'),\n",
       " (1, 'crushing'),\n",
       " (1, 'crazy'),\n",
       " (1, 'court'),\n",
       " (1, 'coronavirus'),\n",
       " (1, 'contagion'),\n",
       " (1, 'concern'),\n",
       " (1, 'by'),\n",
       " (1, 'been'),\n",
       " (1, 'avoid'),\n",
       " (1, 'at'),\n",
       " (1, 'assaulting'),\n",
       " (1, 'appearing'),\n",
       " (1, 'and'),\n",
       " (1, 'an'),\n",
       " (1, 'amongst'),\n",
       " (1, 'after'),\n",
       " (1, 'accused'),\n",
       " (1, 'abuses,'),\n",
       " (1, 'With'),\n",
       " (1, 'We'),\n",
       " (1, 'This'),\n",
       " (1, 'Siu'),\n",
       " (1, 'Psychiatric'),\n",
       " (1, 'Planä¹Ÿæ˜¯ç…§èˆŠçš„~ğŸ™†ğŸ¼\\u200dâ™€ï¸ğŸ™†ğŸ¼\\u200dâ™€ï¸ğŸ’›'),\n",
       " (1, 'Peng'),\n",
       " (1, 'My'),\n",
       " (1, 'MTR'),\n",
       " (1, 'Lam'),\n",
       " (1, 'Kong'),\n",
       " (1, 'Island'),\n",
       " (1, 'Hong'),\n",
       " (1, 'HK,'),\n",
       " (1, 'First'),\n",
       " (1, 'China'),\n",
       " (1, 'Chau'),\n",
       " (1, 'Centre'),\n",
       " (1, 'Causeway'),\n",
       " (1, 'Bâ€¦'),\n",
       " (1, 'Bay'),\n",
       " (1, 'A'),\n",
       " (1, '@rthk_enews:'),\n",
       " (1, '@revmahoney:'),\n",
       " (1, '@nikki_miumiu:'),\n",
       " (1, '@liontigercompu1:'),\n",
       " (1, '@benedictrogers:'),\n",
       " (1, '@SolomonYue'),\n",
       " (1, '@KongMui1:'),\n",
       " (1, '2020å¹´ï¼Œæ’è­¦çˆ¸è€å©†ä¸€å¥èª¬è©±æ¿€å¬²å…¨æ¸¯å¸‚æ°‘ã€‚'),\n",
       " (1, '10113'),\n",
       " (1, '#é¨·'),\n",
       " (1, '#è‰²'),\n",
       " (1, '#æ¸¯å¥³'),\n",
       " (1, '#æ·«è³¤å­¸ç”Ÿå¦¹'),\n",
       " (1, '#æ·«è•©'),\n",
       " (1, '#æ·«æ°´'),\n",
       " (1, '#æ·«å¨ƒ'),\n",
       " (1, '#æ·«å¦¹'),\n",
       " (1, '#æ·«å¥³'),\n",
       " (1, '#æ·«å«'),\n",
       " (1, '#æ’ç•«'),\n",
       " (1, '#æ’åœ–'),\n",
       " (1, '#æ‰‘é‡'),\n",
       " (1, '#å·¨ä¹³â€¦'),\n",
       " (1, '#plan'),\n",
       " (1, '#nochinaextradition'),\n",
       " (1, '#illustrator'),\n",
       " (1, '#illustration'),\n",
       " (1, '#hongkonâ€¦'),\n",
       " (1, '#hkgirl'),\n",
       " (1, '#dx'),\n",
       " (1, '#WuhanCoronavirus'),\n",
       " (1, '#VR2XAN'),\n",
       " (1, '#StandwithHK'),\n",
       " (1, '#PengChauIsland'),\n",
       " (1, '#Huawei'),\n",
       " (1, '#FreeChina'),\n",
       " (1, '#Democraâ€¦'),\n",
       " (1, '#China'),\n",
       " (1, '#CCP'),\n",
       " (1, '\"â€¦')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using earlier function to see common words used in #hongkong\n",
    "user_gist(hk_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12, 'i'),\n",
       " (6, 'pÃ¥'),\n",
       " (6, 'for'),\n",
       " (6, '@MartinBraith'),\n",
       " (5, 'og'),\n",
       " (5, '-'),\n",
       " (4, 'til'),\n",
       " (4, 'den'),\n",
       " (3, 'kampe'),\n",
       " (3, 'er'),\n",
       " (3, 'du'),\n",
       " (3, '@FCBarcelona'),\n",
       " (2, 'ğŸ¥'),\n",
       " (2, 'mod'),\n",
       " (2, 'mere'),\n",
       " (2, 'lykke'),\n",
       " (2, 'indsatsen'),\n",
       " (2, 'ikke'),\n",
       " (2, 'her'),\n",
       " (2, 'et'),\n",
       " (2, 'en'),\n",
       " (2, 'at'),\n",
       " (2, 'Vi'),\n",
       " (2, 'RT'),\n",
       " (2, 'Held'),\n",
       " (2, 'Har'),\n",
       " (1, 'ğŸ™ğŸ‘Š'),\n",
       " (1, 'ğŸ™'),\n",
       " (1, 'ğŸ˜'),\n",
       " (1, 'ğŸ”µâšªï¸â€¦'),\n",
       " (1, 'ğŸ”µâšªï¸'),\n",
       " (1, 'ğŸ”¥'),\n",
       " (1, 'ğŸ“²â€¦'),\n",
       " (1, 'ğŸ“²'),\n",
       " (1, 'ğŸ‘'),\n",
       " (1, 'ğŸ‘ŠğŸ”µâšªï¸'),\n",
       " (1, 'ğŸ‘ŠğŸ‡©ğŸ‡°ğŸ‡ªğŸ‡¸'),\n",
       " (1, 'ğŸ‘Š'),\n",
       " (1, 'ğŸ‡¬ğŸ‡­'),\n",
       " (1, 'ğŸ‡©ğŸ‡°ğŸ‡ªğŸ‡¸'),\n",
       " (1, 'â¬‡ï¸'),\n",
       " (1, 'â˜˜ï¸'),\n",
       " (1, '\\u2066@EsbjergfB\\u2069'),\n",
       " (1, 'Ã¥r'),\n",
       " (1, 'you,'),\n",
       " (1, 'year'),\n",
       " (1, 'weekendens'),\n",
       " (1, 'weekend'),\n",
       " (1, 'vÃ¦re'),\n",
       " (1, 'vores'),\n",
       " (1, 'vi'),\n",
       " (1, 'undvÃ¦re'),\n",
       " (1, 'trÃ¸je'),\n",
       " (1, 'tre'),\n",
       " (1, 'thâ€¦'),\n",
       " (1, 'the'),\n",
       " (1, 'tanker'),\n",
       " (1, 'tak'),\n",
       " (1, 'tager'),\n",
       " (1, 'sÃ¦tter'),\n",
       " (1, 'sÃ¥'),\n",
       " (1, 'stolte'),\n",
       " (1, 'so'),\n",
       " (1, 'sin'),\n",
       " (1, 'sikret'),\n",
       " (1, 'siger'),\n",
       " (1, 'sgu'),\n",
       " (1, 'samtidig'),\n",
       " (1, 'resultat'),\n",
       " (1, 'quizzen'),\n",
       " (1, 'problem.'),\n",
       " (1, 'premieren,'),\n",
       " (1, 'plads:'),\n",
       " (1, 'periode:'),\n",
       " (1, 'ord'),\n",
       " (1, 'opgave'),\n",
       " (1, 'op'),\n",
       " (1, 'on'),\n",
       " (1, 'om'),\n",
       " (1, 'of'),\n",
       " (1, 'nye'),\n",
       " (1, 'nu.'),\n",
       " (1, 'nu'),\n",
       " (1, 'mÃ¥ned'),\n",
       " (1, 'mÃ¥l'),\n",
       " (1, 'mÃ¥'),\n",
       " (1, 'my'),\n",
       " (1, 'morgen'),\n",
       " (1, 'modâ€¦'),\n",
       " (1, 'med'),\n",
       " (1, 'lyt'),\n",
       " (1, 'light'),\n",
       " (1, 'lave'),\n",
       " (1, 'land'),\n",
       " (1, 'kr.'),\n",
       " (1, 'kommende'),\n",
       " (1, 'knee'),\n",
       " (1, 'kigger'),\n",
       " (1, 'hÃ¸jkant'),\n",
       " (1, 'https://t.co/xyov6M2BwD'),\n",
       " (1, 'https://t.co/xxlcO4UPhB'),\n",
       " (1, 'https://t.co/rr5D90xq0w'),\n",
       " (1, 'https://t.co/ncEI7n8PvM'),\n",
       " (1, 'https://t.co/lQQRlD9PHP'),\n",
       " (1, 'https://t.co/krsACPEVH3'),\n",
       " (1, 'https://t.co/kIOOJ4qw3U'),\n",
       " (1, 'https://t.co/iUZXPe104e'),\n",
       " (1, 'https://t.co/iInW8xlUeN'),\n",
       " (1, 'https://t.co/byFCRaGbR2'),\n",
       " (1, 'https://t.co/Sfe6MAY87U'),\n",
       " (1, 'https://t.co/MMU5KCYATB'),\n",
       " (1, 'https://t.co/JhCwEaKlAD'),\n",
       " (1, 'https://t.co/IKdegrmU8H'),\n",
       " (1, 'https://t.co/4DIJiUUQL0'),\n",
       " (1, 'https://t.co/3a2gTEugZ7'),\n",
       " (1, 'high'),\n",
       " (1, 'hentet'),\n",
       " (1, 'have'),\n",
       " (1, 'har'),\n",
       " (1, 'handsker'),\n",
       " (1, 'haft'),\n",
       " (1, 'gÃ¸r'),\n",
       " (1, 'green'),\n",
       " (1, 'godt'),\n",
       " (1, 'fÃ¸lge'),\n",
       " (1, 'fÃ¥r'),\n",
       " (1, 'fylder'),\n",
       " (1, 'fuck'),\n",
       " (1, 'frem'),\n",
       " (1, 'fredags'),\n",
       " (1, 'fra?'),\n",
       " (1, 'forÃ¥rspremieren'),\n",
       " (1, 'first'),\n",
       " (1, 'fantastisk'),\n",
       " (1, 'expectations'),\n",
       " (1, 'endnu,'),\n",
       " (1, 'eller'),\n",
       " (1, 'downloader'),\n",
       " (1, 'donâ€™t'),\n",
       " (1, 'dit'),\n",
       " (1, 'dig!'),\n",
       " (1, 'dig'),\n",
       " (1, 'detâ€¦'),\n",
       " (1, 'det'),\n",
       " (1, 'desvÃ¦rre'),\n",
       " (1, 'debut'),\n",
       " (1, 'dag'),\n",
       " (1, 'burde'),\n",
       " (1, 'bare'),\n",
       " (1, 'backens'),\n",
       " (1, 'app.'),\n",
       " (1, 'affektionsvÃ¦rdi!'),\n",
       " (1, 'af'),\n",
       " (1, 'abonnementskort'),\n",
       " (1, 'Yesterday'),\n",
       " (1, 'Vâ€™s'),\n",
       " (1, 'Truppen'),\n",
       " (1, 'Tre'),\n",
       " (1, 'Tomorrow,'),\n",
       " (1, 'Today'),\n",
       " (1, 'SÃ¸ren'),\n",
       " (1, 'Store'),\n",
       " (1, 'Reese'),\n",
       " (1, 'Play'),\n",
       " (1, 'Perfect'),\n",
       " (1, 'Olsen.'),\n",
       " (1, 'Mathias'),\n",
       " (1, 'Martin'),\n",
       " (1, 'Lyngby'),\n",
       " (1, 'Lars'),\n",
       " (1, 'Kristensen'),\n",
       " (1, 'Kevin'),\n",
       " (1, 'I'),\n",
       " (1, 'Hvilet'),\n",
       " (1, 'Google'),\n",
       " (1, 'Go'),\n",
       " (1, 'Find'),\n",
       " (1, 'FCSB'),\n",
       " (1, 'FCK,'),\n",
       " (1, 'EfB-trÃ¸jen,'),\n",
       " (1, 'EfB-app?'),\n",
       " (1, 'Download'),\n",
       " (1, 'Det'),\n",
       " (1, 'Den'),\n",
       " (1, 'Conboy'),\n",
       " (1, 'Big'),\n",
       " (1, 'App'),\n",
       " (1, '@mo_dauda'),\n",
       " (1, '@kennipoulsen'),\n",
       " (1, '@girondins'),\n",
       " (1, '@brfootball'),\n",
       " (1, '@askrost'),\n",
       " (1, '@adrianpetre98.'),\n",
       " (1, '@Vijay_Chaudhury'),\n",
       " (1, '@ToulouseFC'),\n",
       " (1, '@TelemundoSports'),\n",
       " (1, '@StefanPedersen3:'),\n",
       " (1, '@Somhiseremfcb'),\n",
       " (1, '@LyngbyBoldklub'),\n",
       " (1, '@JesSonnichsen'),\n",
       " (1, '@Halstinho:'),\n",
       " (1, '@FCBarcelona_es'),\n",
       " (1, '@FCBarcelona,'),\n",
       " (1, '@CDLeganes'),\n",
       " (1, '@Boro'),\n",
       " (1, '90mins'),\n",
       " (1, '83'),\n",
       " (1, '79'),\n",
       " (1, '29'),\n",
       " (1, '22'),\n",
       " (1, '#sldk'),\n",
       " (1, '#lbkefb'),\n",
       " (1, '#LaLiga'),\n",
       " (1, '#FCBarcâ€¦')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using function to check commonly used words used by EsbjergfB\n",
    "efb = api.user_timeline('EsbjergfB')\n",
    "user_gist(efb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many tweets have Esbjerg fB made?\n",
    "len(efb)\n",
    "#Gives only 20. Seems unlikely?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Esbjerg, Denmark'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#efb's location\n",
    "efb_user=api.get_user('EsbjergfB')\n",
    "efb_user.location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
